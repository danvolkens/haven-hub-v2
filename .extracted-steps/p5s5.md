## Step 6.1: Create Retry Queue Schema

- **Task**: Create database schema for the error retry queue with exponential backoff.

- **Files**:

### `supabase/migrations/005_retry_queue.sql`
```sql
-- ============================================================================
-- Migration: 005_retry_queue
-- Description: Retry queue for failed operations with exponential backoff
-- Feature: 4 (Error Management)
-- ============================================================================

CREATE TABLE retry_queue (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE NOT NULL,
  
  -- Operation details
  operation_type TEXT NOT NULL,
  payload JSONB NOT NULL,
  
  -- Status tracking
  status TEXT NOT NULL DEFAULT 'pending' 
    CHECK (status IN ('pending', 'processing', 'resolved', 'failed')),
  
  -- Retry tracking
  attempts INTEGER NOT NULL DEFAULT 0,
  max_attempts INTEGER NOT NULL DEFAULT 5,
  last_error TEXT,
  next_retry_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  
  -- Worker claiming (for concurrent safety)
  worker_id TEXT,
  claimed_at TIMESTAMPTZ,
  
  -- Reference to original entity
  reference_id UUID,
  reference_table TEXT,
  
  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  resolved_at TIMESTAMPTZ
);

-- ============================================================================
-- Indexes
-- ============================================================================

-- Primary query: pending items ready for retry
CREATE INDEX idx_retry_queue_pending 
  ON retry_queue(user_id, status, next_retry_at)
  WHERE status = 'pending';

-- Find by worker
CREATE INDEX idx_retry_queue_worker
  ON retry_queue(worker_id, status)
  WHERE worker_id IS NOT NULL;

-- Find by operation type
CREATE INDEX idx_retry_queue_operation
  ON retry_queue(user_id, operation_type, status);

-- Find by reference
CREATE INDEX idx_retry_queue_reference
  ON retry_queue(reference_id, reference_table)
  WHERE reference_id IS NOT NULL;

-- ============================================================================
-- Row Level Security
-- ============================================================================
ALTER TABLE retry_queue ENABLE ROW LEVEL SECURITY;

CREATE POLICY retry_queue_select ON retry_queue
  FOR SELECT USING (user_id = auth.uid());

CREATE POLICY retry_queue_insert ON retry_queue
  FOR INSERT WITH CHECK (user_id = auth.uid());

CREATE POLICY retry_queue_update ON retry_queue
  FOR UPDATE USING (user_id = auth.uid());

-- ============================================================================
-- Trigger for updated_at
-- ============================================================================
CREATE TRIGGER retry_queue_updated_at
  BEFORE UPDATE ON retry_queue
  FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

-- ============================================================================
-- Function: Claim items for processing (concurrent-safe)
-- ============================================================================
CREATE OR REPLACE FUNCTION claim_retry_items(
  p_worker_id TEXT,
  p_limit INTEGER DEFAULT 10
)
RETURNS SETOF retry_queue AS $$
BEGIN
  RETURN QUERY
  UPDATE retry_queue
  SET 
    status = 'processing',
    worker_id = p_worker_id,
    claimed_at = NOW(),
    attempts = attempts + 1
  WHERE id IN (
    SELECT id FROM retry_queue
    WHERE status = 'pending'
      AND next_retry_at <= NOW()
    ORDER BY next_retry_at ASC
    LIMIT p_limit
    FOR UPDATE SKIP LOCKED
  )
  RETURNING *;
END;
$$ LANGUAGE plpgsql;

-- ============================================================================
-- Function: Queue an operation for retry
-- ============================================================================
CREATE OR REPLACE FUNCTION queue_for_retry(
  p_user_id UUID,
  p_operation_type TEXT,
  p_payload JSONB,
  p_error TEXT DEFAULT NULL,
  p_reference_id UUID DEFAULT NULL,
  p_reference_table TEXT DEFAULT NULL,
  p_max_attempts INTEGER DEFAULT 5
)
RETURNS UUID AS $$
DECLARE
  v_id UUID;
BEGIN
  INSERT INTO retry_queue (
    user_id,
    operation_type,
    payload,
    last_error,
    reference_id,
    reference_table,
    max_attempts
  ) VALUES (
    p_user_id,
    p_operation_type,
    p_payload,
    p_error,
    p_reference_id,
    p_reference_table,
    p_max_attempts
  )
  RETURNING id INTO v_id;
  
  RETURN v_id;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

-- ============================================================================
-- Scheduled Exports Table
-- ============================================================================
CREATE TABLE scheduled_exports (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE NOT NULL,
  
  -- Export configuration
  export_type TEXT NOT NULL,
  format TEXT NOT NULL DEFAULT 'csv' CHECK (format IN ('csv', 'json')),
  field_selection TEXT[],
  date_range_type TEXT CHECK (date_range_type IN ('last_week', 'last_month', 'all_time')),
  
  -- Schedule
  frequency TEXT NOT NULL CHECK (frequency IN ('weekly', 'monthly')),
  enabled BOOLEAN NOT NULL DEFAULT true,
  
  -- Delivery
  delivery_method TEXT NOT NULL DEFAULT 'email' CHECK (delivery_method IN ('email', 'download')),
  delivery_email TEXT,
  
  -- Tracking
  last_run_at TIMESTAMPTZ,
  next_run_at TIMESTAMPTZ NOT NULL,
  
  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

CREATE INDEX idx_scheduled_exports_next_run 
  ON scheduled_exports(next_run_at)
  WHERE enabled = true;

ALTER TABLE scheduled_exports ENABLE ROW LEVEL SECURITY;

CREATE POLICY scheduled_exports_all ON scheduled_exports
  FOR ALL USING (user_id = auth.uid());

CREATE TRIGGER scheduled_exports_updated_at
  BEFORE UPDATE ON scheduled_exports
  FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
```

- **Step Dependencies**: Step 2.1
- **User Instructions**: Run migration

---

